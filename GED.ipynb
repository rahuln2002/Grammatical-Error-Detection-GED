{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Grammer Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWUl3T1ov1Gz",
    "outputId": "73216eb9-3f51-441b-be41-642001b4c2ec"
   },
   "outputs": [],
   "source": [
    "# Install the latest version of the 'transformers' library directly from the Hugging Face GitHub repository\n",
    "# The '--quiet' flag suppresses the output for a cleaner installation process\n",
    "%pip install --quiet git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the current status of the NVIDIA GPU, including memory usage, GPU utilization, and running processes\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\tImporting Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings to keep the output clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import necessary libraries for model training and evaluation\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle  # Shuffle data for randomness in training and validation splits\n",
    "from transformers import RobertaTokenizer, BertTokenizer  # Tokenizers for Roberta and Bert models\n",
    "from torch.utils.data import TensorDataset  # Dataset to hold input/output tensors\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler  # DataLoader for batching and shuffling\n",
    "from transformers import BertForSequenceClassification, BertConfig, RobertaForSequenceClassification  # Pretrained models for classification tasks\n",
    "from transformers import AdamW  # Optimizer for training\n",
    "import numpy as np\n",
    "from transformers import get_linear_schedule_with_warmup  # Learning rate scheduler\n",
    "import time  # Track time for training and evaluation\n",
    "import datetime  # Format time into a readable format\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # For evaluation metrics\n",
    "import random  # Set random seeds for reproducibility\n",
    "import matplotlib.pyplot as plt  # Plotting for visualizing training progress\n",
    "%matplotlib inline  # Enable inline plotting for Jupyter Notebooks\n",
    "import seaborn as sns  # For creating better plots\n",
    "import weightwatcher as ww  # For monitoring the training process and analyzing weight changes\n",
    "import os  # To handle file and directory operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksXDKdkr0dho",
    "outputId": "7aa60ff5-414a-4758-c4e4-c0b7b8c9530c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use the GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly (use GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the name of the GPU being used (if available)\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and transforming data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned Lang-8 dataset into a DataFrame\n",
    "df_lang_0 = pd.read_csv('./Cleaned_Lang8_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plsFULc9wKTA",
    "outputId": "f0cf1d52-09e4-4241-d5c4-8ab723b5bd1b"
   },
   "outputs": [],
   "source": [
    "# Select the first 90,000 sentences from column '0', assign label 0, and rename the column to 'sentence'\n",
    "df_lang_t0 = df_lang_0[0:90000]['0'].to_frame()\n",
    "df_lang_t0['label'] = 0\n",
    "df_lang_t0 = df_lang_t0.rename(columns={'0': 'sentence'})\n",
    "\n",
    "# Select sentences from rows 110,000 to 200,000 from column '1', assign label 1, and rename the column to 'sentence'\n",
    "df_lang_t1 = df_lang_0[110000:200000]['1'].to_frame()\n",
    "df_lang_t1['label'] = 1\n",
    "df_lang_t1 = df_lang_t1.rename(columns={'1': 'sentence'})\n",
    "\n",
    "# Combine the labeled dataframes for training and shuffle the rows\n",
    "df_train = pd.concat([df_lang_t0, df_lang_t1], ignore_index=True)\n",
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set by sampling 10,000 sentences from rows 90,000 to 100,000 in column '0', assign label 0, and rename the column\n",
    "df_val0 = df_lang_0[90000:100000]['0'].sample(10000).to_frame()\n",
    "df_val0['label'] = 0\n",
    "df_val0 = df_val0.rename(columns={'0': 'sentence'})\n",
    "\n",
    "# Create a validation set by sampling 10,000 sentences from rows 100,000 to 110,000 in column '1', assign label 1, and rename the column\n",
    "df_val1 = df_lang_0[100000:110000]['1'].sample(10000).to_frame()\n",
    "df_val1['label'] = 1\n",
    "df_val1 = df_val1.rename(columns={'1': 'sentence'})\n",
    "\n",
    "# Combine the validation dataframes and shuffle the rows\n",
    "df_val = pd.concat([df_val0, df_val1], ignore_index=True)\n",
    "df_val = shuffle(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of sentences in the training and validation sets\n",
    "print('Number of training sentences: {:,}'.format(df_train.shape[0]))\n",
    "print('Number of validation sentences: {:,}'.format(df_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hte67LxZBZ40",
    "outputId": "8afca454-4512-4254-c5ab-e00cc4ee028d"
   },
   "outputs": [],
   "source": [
    "df_train['label'].value_counts(), df_val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training sentences and their corresponding labels from the training DataFrame\n",
    "sentences_train = df_train.sentence.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "# Extract validation sentences and their corresponding labels from the validation DataFrame\n",
    "sentences_val = df_val.sentence.values\n",
    "labels_val = df_val.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0A1N0IExFFt",
    "outputId": "eeac9aff-163a-4f3b-f821-46b4740167bb"
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer for RoBERTa (or BERT, commented out)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training data\n",
    "input_ids_train = []  # List to store tokenized input IDs for training data\n",
    "attention_masks_train = []  # List to store attention masks for training data\n",
    "\n",
    "# Tokenize each training sentence and create input IDs and attention masks\n",
    "for sent in sentences_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # The sentence to encode\n",
    "        add_special_tokens=True,   # Add [CLS] and [SEP] tokens\n",
    "        max_length=64,             # Truncate sentences to a maximum length of 64\n",
    "        pad_to_max_length=True,    # Pad sentences shorter than 64 to this length\n",
    "        return_attention_mask=True,  # Generate attention masks\n",
    "        return_tensors='pt',       # Return PyTorch tensors\n",
    "    )\n",
    "    input_ids_train.append(encoded_dict['input_ids'])  # Append tokenized input IDs\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])  # Append attention masks\n",
    "\n",
    "# Convert lists to tensors for PyTorch\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(labels_train)  # Convert labels to a tensor\n",
    "\n",
    "# Create a TensorDataset for training data\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "\n",
    "\n",
    "# Preparing the validation data\n",
    "input_ids_val = []  # List to store tokenized input IDs for validation data\n",
    "attention_masks_val = []  # List to store attention masks for validation data\n",
    "\n",
    "# Tokenize each validation sentence and create input IDs and attention masks\n",
    "for sent in sentences_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # The sentence to encode\n",
    "        add_special_tokens=True,   # Add [CLS] and [SEP] tokens\n",
    "        max_length=64,             # Truncate sentences to a maximum length of 64\n",
    "        pad_to_max_length=True,    # Pad sentences shorter than 64 to this length\n",
    "        return_attention_mask=True,  # Generate attention masks\n",
    "        return_tensors='pt',       # Return PyTorch tensors\n",
    "    )\n",
    "    input_ids_val.append(encoded_dict['input_ids'])  # Append tokenized input IDs\n",
    "    attention_masks_val.append(encoded_dict['attention_mask'])  # Append attention masks\n",
    "\n",
    "# Convert lists to tensors for PyTorch\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "labels_val = torch.tensor(labels_val)  # Convert labels to a tensor\n",
    "\n",
    "# Create a TensorDataset for validation data\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batching and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Define the batch size for both training and validation\n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "# RandomSampler shuffles the data at each epoch for better generalization\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train,              # The training dataset\n",
    "    sampler=RandomSampler(dataset_train),  # Random sampling\n",
    "    batch_size=batch_size       # Number of samples per batch\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the validation data\n",
    "# SequentialSampler ensures data is not shuffled for evaluation\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset_val,                # The validation dataset\n",
    "    sampler=SequentialSampler(dataset_val),  # Sequential sampling\n",
    "    batch_size=batch_size       # Number of samples per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQaNI1y85PAW",
    "outputId": "6212a287-4994-4df6-d12c-7520d839c325"
   },
   "outputs": [],
   "source": [
    "# Initialize the RoBERTa model for sequence classification with 2 output labels\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",           # Pretrained model to use ('roberta-base' or 'roberta-large')\n",
    "    num_labels=2,             # Number of output labels (binary classification)\n",
    "    output_attentions=False,  # Do not return attention weights\n",
    "    output_hidden_states=False  # Do not return hidden states\n",
    ")\n",
    "\n",
    "# Adjust the dropout rate for the last encoder layer and the classifier layer to 0.65 for better regularization\n",
    "model.roberta.encoder.layer[-1].output.dropout = torch.nn.Dropout(0.65)  # type: ignore\n",
    "model.classifier.dropout = torch.nn.Dropout(0.65)  # type: ignore\n",
    "\n",
    "# Move the model to the specified device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Initialize the BERT model for sequence classification (commented out)\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\",        # Pretrained model to use ('bert-base-uncased' or 'bert-large-uncased')\n",
    "#     num_labels=2,              # Number of output labels (binary classification)\n",
    "#     output_attentions=False,   # Do not return attention weights\n",
    "#     output_hidden_states=False  # Do not return hidden states\n",
    "# )\n",
    "# Adjust the dropout rate for the last encoder layer and the classifier layer to 0.65 for better regularization\n",
    "# model.bert.encoder.layer[-1].output.dropout = torch.nn.Dropout(0.65)  # type: ignore\n",
    "# model.classifier.dropout = torch.nn.Dropout(0.65)  # type: ignore\n",
    "\n",
    "# Move the model to the specified device (GPU or CPU)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting initial parameters and selecting layers to freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a copy of the initial parameters of the model for potential reference or comparison\n",
    "initial_params = {}\n",
    "for name, param in model.named_parameters():  # Iterate through all model parameters\n",
    "    initial_params[name] = param.clone().detach()  # Clone and detach each parameter to avoid altering the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the layers to freeze (prevent updates during training) by their parameter names\n",
    "layers_to_freeze = [\n",
    "    'bert.encoder.layer.9.attention.self.value',     # Layer 9 attention self-value\n",
    "    'bert.encoder.layer.11.attention.self.value',   # Layer 11 attention self-value\n",
    "    'bert.encoder.layer.11.attention.output.dense'  # Layer 11 attention output dense\n",
    "]\n",
    "\n",
    "# Iterate through model parameters and freeze the specified layers\n",
    "for name, param in model.named_parameters():  # Iterate through all model parameters\n",
    "    if any(layer in name for layer in layers_to_freeze):  # Check if the parameter belongs to the specified layers\n",
    "        param.requires_grad = False  # Freeze the parameter (no gradient updates during training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the model by disabling gradient updates\n",
    "for param in model.parameters():  # Iterate through all model parameters\n",
    "    param.requires_grad = False  # Disable gradient computation for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the layers to unfreeze (enable updates during training) by their parameter names\n",
    "layers_to_unfreeze = [\n",
    "    'bert.encoder.layer.7.attention.output.dense',   # Layer 7 attention output dense\n",
    "    'bert.encoder.layer.8.attention.self.value',    # Layer 8 attention self-value\n",
    "    'bert.encoder.layer.9.attention.self.value',    # Layer 9 attention self-value\n",
    "    'bert.encoder.layer.11.attention.self.value',   # Layer 11 attention self-value\n",
    "    'bert.encoder.layer.11.attention.output.dense'  # Layer 11 attention output dense\n",
    "]\n",
    "\n",
    "# Iterate through model parameters and selectively unfreeze the specified layers\n",
    "for name, param in model.named_parameters():  # Iterate through all model parameters with their names\n",
    "    if any(layer in name for layer in layers_to_unfreeze):  # Check if the parameter belongs to the specified layers\n",
    "        param.requires_grad = True  # Enable gradient computation for the specified layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all parameters in the last encoder layer of the BERT model (Layer -1)\n",
    "for param in model.bert.encoder.layer[-1].parameters():  # Iterate through all parameters in the last encoder layer\n",
    "    param.requires_grad = True  # Enable gradient computation for the last encoder layer's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Optimizer, Epochs, Steps and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN-zUxVb5h9s",
    "outputId": "f39d9f5e-7883-4440-c396-19fc30332bdf"
   },
   "outputs": [],
   "source": [
    "# Initialize the AdamW optimizer with weight decay for regularization\n",
    "# The commented line would filter parameters based on whether they require gradients (i.e., only trainable parameters)\n",
    "# Used when freezing layers\n",
    "# optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr = 2e-5, eps = 1e-8, weight_decay=0.2)\n",
    "\n",
    "# Current optimizer setup: AdamW for all model parameters with a learning rate of 2e-5, epsilon of 1e-8, and weight decay of 0.5\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "a2uS1C6d5wo4"
   },
   "outputs": [],
   "source": [
    "# Set the number of training epochs\n",
    "epochs = 4\n",
    "\n",
    "# Calculate the total number of steps based on the number of training batches and epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Initialize a learning rate scheduler (linear warm-up followed by linear decay) for gradual learning rate adjustment\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,                # The optimizer to adjust the learning rate for\n",
    "    num_warmup_steps=0,       # No warm-up steps, meaning the learning rate starts immediately at the initial value\n",
    "    num_training_steps=total_steps  # Total number of training steps (batches * epochs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined functions to calculate accuracy, time and prediction, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2gnfEaNF54nn"
   },
   "outputs": [],
   "source": [
    "# Function to compute the accuracy of model predictions\n",
    "def flat_accuracy(preds, labels):\n",
    "    # Flatten the predicted values and labels, then compute accuracy\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()  # Get the predicted class by finding the max value\n",
    "    labels_flat = labels.flatten()  # Flatten the true labels\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)  # Calculate accuracy as the ratio of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vZVM07kG5_m7"
   },
   "outputs": [],
   "source": [
    "# Function to format elapsed time into a more readable format (HH:MM:SS)\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))  # Round elapsed time to nearest integer\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))  # Convert seconds to a string representation of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fVaHKCL4qvig"
   },
   "outputs": [],
   "source": [
    "# Function to obtain model predictions and labels from the dataloader\n",
    "def get_predictions_and_labels(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout layers)\n",
    "\n",
    "    all_preds = []  # List to store all predictions\n",
    "    all_labels = []  # List to store all true labels\n",
    "\n",
    "    # Iterate through batches in the dataloader\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)  # Move the batch data to the specified device (GPU/CPU)\n",
    "        b_input_ids, b_input_mask, b_labels = batch  # Unpack batch into input IDs, attention masks, and labels\n",
    "\n",
    "        # Disable gradient computation for evaluation (no backpropagation needed)\n",
    "        with torch.no_grad():\n",
    "            # Get model outputs\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,  # No token type IDs for single-sentence classification\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels,\n",
    "                            return_dict=True)  # Return outputs as a dictionary\n",
    "\n",
    "        # Extract logits from model output (the raw predictions)\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[1]  # If the output is a tuple, the second element is logits\n",
    "        elif isinstance(outputs, dict):\n",
    "            logits = outputs['logits']  # If the output is a dictionary, get logits from the 'logits' key\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model output format\")  # Raise error if output format is unsupported\n",
    "\n",
    "        # Get predictions by choosing the class with the highest probability\n",
    "        preds = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "        labels = b_labels.cpu().numpy()  # Convert labels to numpy for easier handling\n",
    "\n",
    "        # Store predictions and labels\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    return all_preds, all_labels  # Return all predictions and labels for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning/Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility across all libraries (random, numpy, torch)\n",
    "seed_val = 42\n",
    "random.seed(seed_val)  # Set seed for Python's random module\n",
    "np.random.seed(seed_val)  # Set seed for NumPy\n",
    "torch.manual_seed(seed_val)  # Set seed for PyTorch on CPU\n",
    "torch.cuda.manual_seed_all(seed_val)  # Set seed for all GPUs if available\n",
    "\n",
    "# Initialize a list to store training statistics across epochs\n",
    "training_stats = []\n",
    "\n",
    "# Track total time for training\n",
    "total_t0 = time.time()\n",
    "\n",
    "# Loop over each epoch for training\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Track time for the current epoch\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Initialize metrics for tracking training progress\n",
    "    total_train_loss = 0\n",
    "    total_train_accuracy = 0\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    # Iterate through each batch in the training dataloader\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Print progress every 40 steps\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,} of {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Move the batch to the appropriate device (GPU or CPU)\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Zero the gradients before backward pass\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        loss, logits = model(b_input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels,\n",
    "                             return_dict=False)  # Get loss and logits from the model\n",
    "\n",
    "        # Accumulate training loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Convert logits and labels to numpy for accuracy computation\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Perform backward pass (gradient calculation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate using the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accumulate training accuracy\n",
    "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Compute average training accuracy and loss for the epoch\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
    "    print(\"Training Accuracy: {0:.2f}%\".format(avg_train_accuracy * 100))\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Format and print training time for the epoch\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"Training Loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Training took: {:}\".format(training_time))\n",
    "\n",
    "    # Run validation after each epoch\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # Track time for the validation phase\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize metrics for validation\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    # Iterate through validation batches\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Disable gradient calculation during validation\n",
    "        with torch.no_grad():\n",
    "            # Perform forward pass during validation\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 token_type_ids=None,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels,\n",
    "                                 return_dict=False)\n",
    "\n",
    "        # Accumulate validation loss\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Convert logits and labels to numpy for accuracy computation\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Accumulate validation accuracy\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Compute average validation accuracy and loss\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"Validation Accuracy: {0:.2f}%\".format(avg_val_accuracy * 100))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Format and print validation time\n",
    "    validation_time = format_time(time.time() - t1)\n",
    "    print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Append epoch stats to the training statistics list\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Accur.': avg_train_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Loss': avg_val_loss,\n",
    "            'Test Accur.': avg_val_accuracy,\n",
    "            'Test Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Print training completion message\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting updated parameters and calculating changes (Used when using freeze layers part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters to CPU and check for changes between initial and updated parameters\n",
    "updated_params = {name: param.cpu() for name, param in model.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the updated parameters with the initial ones\n",
    "for name, param in updated_params.items():\n",
    "    # If the parameter has changed, print details of the change\n",
    "    if not torch.allclose(initial_params[name].cpu().detach(), param):\n",
    "        print(f\"Parameter {name} changed:\")\n",
    "        print(f\"\\tShape: {initial_params[name].shape}\")\n",
    "        print(f\"\\tPrevious Value: {initial_params[name].cpu().detach().numpy()}\")\n",
    "        print(f\"\\tShape: {updated_params[name].shape}\")\n",
    "        print(f\"\\tNew Value: {param.cpu().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert initial parameters to NumPy arrays\n",
    "initial_params_cpu = {name: param.cpu().detach().numpy() for name, param in initial_params.items()}\n",
    "# Convert updated parameters to NumPy arrays\n",
    "updated_params_cpu = {name: param.cpu().detach().numpy() for name, param in updated_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage change for each parameter\n",
    "percentage_change = {}\n",
    "for name in initial_params_cpu.keys():\n",
    "    # Calculate the absolute difference and normalized change percentage\n",
    "    numerator = np.abs(updated_params_cpu[name] - initial_params_cpu[name])\n",
    "    denominator = np.maximum(np.abs(initial_params_cpu[name]), np.abs(updated_params_cpu[name]))\n",
    "    percentage_change[name] = (numerator / denominator) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and standard deviation of percentage change for each parameter\n",
    "mean_percentage_change = {name: np.mean(change) for name, change in percentage_change.items()}\n",
    "std_percentage_change = {name: np.std(change) for name, change in percentage_change.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the mean and std of percentage changes\n",
    "df = pd.DataFrame({\n",
    "    'Parameter': list(initial_params_cpu.keys()),\n",
    "    'Mean Percentage Change': list(mean_percentage_change.values()),\n",
    "    'Std Percentage Change': list(std_percentage_change.values())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"Param_percent_change_mean_std_roberta_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and retrieve the parameters of the classifier's linear layer (weights)\n",
    "linear_layer_params = None\n",
    "for name, param in model.named_parameters():\n",
    "    # Look for the classifier weight parameter in the model\n",
    "    if 'classifier.weight' in name:\n",
    "        linear_layer_params = param\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data of the linear layer weights\n",
    "linear_layer_params.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting predictions, labels with classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZvppswE1vnT"
   },
   "outputs": [],
   "source": [
    "# Get predictions and labels from the validation set\n",
    "val_preds, val_labels = get_predictions_and_labels(model, validation_dataloader)\n",
    "\n",
    "# Compute the confusion matrix based on the true labels and predicted labels\n",
    "conf_mat_validation = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Extract values from the confusion matrix (True Positives, False Positives, False Negatives, True Negatives)\n",
    "TN_val, FP_val, FN_val, TP_val = conf_mat_validation.ravel()\n",
    "\n",
    "# Print out the values of the confusion matrix for the validation set\n",
    "print(\"Validation Set:\")\n",
    "print(f\"True Positives (TP): {TP_val}\")\n",
    "print(f\"True Negatives (TN): {TN_val}\")\n",
    "print(f\"False Negatives (FN): {FN_val}\")\n",
    "print(f\"False Positives (FP): {FP_val}\")\n",
    "\n",
    "# Generate and print the classification report, which includes precision, recall, and F1-score\n",
    "cr_val = classification_report(val_labels, val_preds)\n",
    "print(cr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using WeightWatcher to analyze model layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WeightWatcher object with the model\n",
    "watcher = ww.WeightWatcher(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the model's weights using the WeightWatcher\n",
    "analyze = watcher.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the detailed information about the model's weights and their analysis\n",
    "details = watcher.get_details()\n",
    "\n",
    "# Save the detailed analysis of the weights to a CSV file\n",
    "details.to_csv(\"all_UT_freezed.csv\", index=False) # type: ignore\n",
    "\n",
    "# Display the detailed analysis of the model's weights\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display a summary of the model's weight analysis\n",
    "watcher.get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training stats and plotting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "IVZYN3OF8zWM",
    "outputId": "04351f70-a7d6-4d65-ee2b-d9ec38061fbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accur.</th>\n",
       "      <th>Test Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.342279</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0:59:17</td>\n",
       "      <td>0.375627</td>\n",
       "      <td>0.89105</td>\n",
       "      <td>0:01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217442</td>\n",
       "      <td>0.917861</td>\n",
       "      <td>0:59:49</td>\n",
       "      <td>0.375876</td>\n",
       "      <td>0.90275</td>\n",
       "      <td>0:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148877</td>\n",
       "      <td>0.948278</td>\n",
       "      <td>0:59:29</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.90420</td>\n",
       "      <td>0:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104273</td>\n",
       "      <td>0.967822</td>\n",
       "      <td>0:59:37</td>\n",
       "      <td>0.530868</td>\n",
       "      <td>0.90470</td>\n",
       "      <td>0:02:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Training Accur. Training Time  Test Loss  Test Accur.  \\\n",
       "epoch                                                                         \n",
       "1           0.342279         0.858011       0:59:17   0.375627      0.89105   \n",
       "2           0.217442         0.917861       0:59:49   0.375876      0.90275   \n",
       "3           0.148877         0.948278       0:59:29   0.412361      0.90420   \n",
       "4           0.104273         0.967822       0:59:37   0.530868      0.90470   \n",
       "\n",
       "      Test Time  \n",
       "epoch            \n",
       "1       0:01:59  \n",
       "2       0:02:00  \n",
       "3       0:02:00  \n",
       "4       0:02:01  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the training statistics into a DataFrame for easier manipulation and visualization\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')  # Set 'epoch' as the index for better clarity\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "81JXPVi-83St",
    "outputId": "29bd8153-1266-40c6-f62d-9b7cab72679f"
   },
   "outputs": [],
   "source": [
    "# Plotting Loss for Training and Testing\n",
    "\n",
    "# Set the visual style for the plot\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)  # Increase font size for readability\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)  # Set figure size\n",
    "\n",
    "# Plot the Training Loss and Test Loss for each epoch\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")  # Training loss in blue\n",
    "plt.plot(df_stats['Test Loss'], 'r-o', label=\"Testing\")  # Test loss in red\n",
    "\n",
    "# Add title, labels, and legend to the plot\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks(range(1, epochs+1))  # Set x-axis ticks for each epoch\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Plotting Accuracy for Training and Testing\n",
    "\n",
    "# Set the visual style for the accuracy plot (same as above)\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Plot the Training Accuracy and Test Accuracy for each epoch\n",
    "plt.plot(df_stats['Training Accur.'], 'b-o', label=\"Training\")  # Training accuracy in blue\n",
    "plt.plot(df_stats['Test Accur.'], 'r-o', label=\"Testing\")  # Test accuracy in red\n",
    "\n",
    "# Add title, labels, and legend to the accuracy plot\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(range(1, epochs+1))  # Set x-axis ticks for each epoch\n",
    "\n",
    "# Display the accuracy plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory where the model and tokenizer will be saved\n",
    "output_dir = './model_20k_roberta_base/'\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Print a message indicating where the model will be saved\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Determine whether the model is wrapped in a DataParallel module and save the model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Ensure saving the model correctly\n",
    "model_to_save.save_pretrained(output_dir)  # Save the model's weights and configuration\n",
    "tokenizer.save_pretrained(output_dir)  # Save the tokenizer configuration and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint dictionary to save the optimizer and scheduler states\n",
    "checkpoint = {\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # Save the optimizer's state\n",
    "    'scheduler_state_dict': scheduler.state_dict(),  # Save the scheduler's state\n",
    "}\n",
    "\n",
    "# Save the checkpoint (optimizer and scheduler states) to the output directory\n",
    "torch.save(checkpoint, os.path.join(output_dir, 'optimizer_scheduler_checkpoint.pth'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
